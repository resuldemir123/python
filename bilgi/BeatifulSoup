Elbette! **Beautiful Soup**, Python'da web sayfalarÄ±ndan veri Ã§ekmek (web scraping) iÃ§in kullanÄ±lan popÃ¼ler bir kÃ¼tÃ¼phanedir. HTML ve XML dokÃ¼manlarÄ±nÄ± ayrÄ±ÅŸtÄ±rarak (parse), belirli verilere kolayca eriÅŸmenizi saÄŸlar. AÅŸaÄŸÄ±da Beautiful Soup ile ilgili detaylÄ± bilgiler bulabilirsiniz.

---

## **Beautiful Soup Nedir?**
Beautiful Soup, HTML ve XML dokÃ¼manlarÄ±nÄ± ayrÄ±ÅŸtÄ±rmak iÃ§in kullanÄ±lan bir Python kÃ¼tÃ¼phanesidir. Web sayfalarÄ±ndan veri Ã§ekmek (web scraping) iÃ§in sÄ±klÄ±kla kullanÄ±lÄ±r. Ã–zellikle, karmaÅŸÄ±k HTML yapÄ±larÄ±nÄ± kolayca iÅŸleyebilir ve belirli etiketlere, sÄ±nÄ±flara veya ID'lere gÃ¶re veri Ã§ekebilir.

---

## **Beautiful Soup Kurulumu**
Beautiful Soup'u kullanmak iÃ§in Ã¶ncelikle kurulum yapmanÄ±z gerekiyor.

### **1. Beautiful Soup Kurma**
Terminal veya komut satÄ±rÄ±nda aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
```bash
pip install beautifulsoup4
```

### **2. requests KÃ¼tÃ¼phanesi Kurma**
Beautiful Soup, genellikle web sayfalarÄ±nÄ± indirmek iÃ§in `requests` kÃ¼tÃ¼phanesiyle birlikte kullanÄ±lÄ±r. EÄŸer `requests` kurulu deÄŸilse, aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
```bash
pip install requests
```

---

## **Beautiful Soup Temel KullanÄ±mÄ±**

### **1. Web SayfasÄ±nÄ± Ä°ndirme ve AyrÄ±ÅŸtÄ±rma**
```python
import requests
from bs4 import BeautifulSoup

# Web sayfasÄ±nÄ± indir
url = "https://example.com"
response = requests.get(url)

# Beautiful Soup ile ayrÄ±ÅŸtÄ±r
soup = BeautifulSoup(response.text, "html.parser")

# HTML iÃ§eriÄŸini yazdÄ±r
print(soup.prettify())
```

---

### **2. Etiketlere EriÅŸim**
Beautiful Soup, HTML etiketlerine kolayca eriÅŸmenizi saÄŸlar.

#### **Ã–rnek: BaÅŸlÄ±k Etiketini Bulma**
```python
title = soup.title
print(title.text)  # BaÅŸlÄ±k metnini yazdÄ±r
```

#### **Ã–rnek: TÃ¼m BaÄŸlantÄ±larÄ± Bulma**
```python
for link in soup.find_all("a"):
    print(link.get("href"))  # BaÄŸlantÄ±larÄ± yazdÄ±r
```

---

### **3. SÄ±nÄ±f ve ID ile Arama**
Beautiful Soup, belirli sÄ±nÄ±f veya ID'lere sahip elementleri bulmak iÃ§in kullanÄ±lÄ±r.

#### **Ã–rnek: Belirli Bir SÄ±nÄ±fa Sahip Elementleri Bulma**
```python
for element in soup.find_all(class_="example-class"):
    print(element.text)
```

#### **Ã–rnek: Belirli Bir ID'ye Sahip Elementi Bulma**
```python
element = soup.find(id="example-id")
print(element.text)
```

---

### **4. CSS SeÃ§icileri Kullanma**
Beautiful Soup, CSS seÃ§icileri kullanarak elementleri bulmayÄ± destekler.

#### **Ã–rnek: CSS SeÃ§icisi ile Arama**
```python
elements = soup.select("div.example-class > p")
for element in elements:
    print(element.text)
```

---

## **Beautiful Soup ile Web Scraping Ã–rneÄŸi**
AÅŸaÄŸÄ±da, bir web sayfasÄ±ndan baÅŸlÄ±klarÄ± ve baÄŸlantÄ±larÄ± Ã§eken basit bir Ã¶rnek bulunmaktadÄ±r.

```python
import requests
from bs4 import BeautifulSoup

# Web sayfasÄ±nÄ± indir
url = "https://example.com"
response = requests.get(url)

# Beautiful Soup ile ayrÄ±ÅŸtÄ±r
soup = BeautifulSoup(response.text, "html.parser")

# BaÅŸlÄ±klarÄ± ve baÄŸlantÄ±larÄ± bul
for heading in soup.find_all("h1"):
    print(heading.text)

for link in soup.find_all("a"):
    print(link.get("href"))
```

---

## **Beautiful Soup ile Ä°leri DÃ¼zey Ä°ÅŸlemler**

### **1. Verileri Filtreleme**
Beautiful Soup, belirli Ã¶zelliklere sahip elementleri filtrelemek iÃ§in kullanÄ±labilir.

#### **Ã–rnek: Belirli Bir Ã–zelliÄŸe Sahip Elementleri Bulma**
```python
for element in soup.find_all("a", href=True):
    if "example" in element["href"]:
        print(element["href"])
```

---

### **2. Verileri CSV'ye Kaydetme**
Ã‡ekilen verileri bir CSV dosyasÄ±na kaydedebilirsiniz.

#### **Ã–rnek:**
```python
import csv

# CSV dosyasÄ±nÄ± aÃ§
with open("output.csv", "w", newline="", encoding="utf-8") as file:
    writer = csv.writer(file)
    writer.writerow(["BaÅŸlÄ±k", "BaÄŸlantÄ±"])  # BaÅŸlÄ±k satÄ±rÄ±

    # Verileri yaz
    for heading in soup.find_all("h1"):
        writer.writerow([heading.text, ""])

    for link in soup.find_all("a"):
        writer.writerow(["", link.get("href")])
```

---

### **3. Dinamik Sayfalarda Web Scraping**
Beautiful Soup, yalnÄ±zca statik HTML sayfalarÄ±nÄ± ayrÄ±ÅŸtÄ±rÄ±r. Dinamik sayfalar iÃ§in **Selenium** gibi bir araÃ§ kullanmanÄ±z gerekir.

---

## **Beautiful Soup ile Ä°lgili Ä°puÃ§larÄ±**
1. **Hata YÃ¶netimi:** Web sayfalarÄ±na eriÅŸirken hata yÃ¶netimi yapÄ±n.
   ```python
   try:
       response = requests.get(url)
       response.raise_for_status()  # HTTP hatalarÄ±nÄ± kontrol et
   except requests.exceptions.RequestException as e:
       print(f"Hata: {e}")
   ```

2. **KullanÄ±cÄ± AracÄ±sÄ± (User-Agent) Ekleme:** BazÄ± web siteleri, botlarÄ± engellemek iÃ§in kullanÄ±cÄ± aracÄ±sÄ±nÄ± kontrol eder. Bu durumda, bir kullanÄ±cÄ± aracÄ±sÄ± ekleyebilirsiniz.
   ```python
   headers = {
       "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
   }
   response = requests.get(url, headers=headers)
   ```

3. **Gizli Bilgiler:** Web scraping yaparken, web sitelerinin kullanÄ±m koÅŸullarÄ±na ve gizlilik politikalarÄ±na dikkat edin.

---

## **SonuÃ§**
Beautiful Soup, Python'da web scraping yapmak iÃ§in gÃ¼Ã§lÃ¼ ve kullanÄ±mÄ± kolay bir kÃ¼tÃ¼phanedir. HTML ve XML dokÃ¼manlarÄ±nÄ± ayrÄ±ÅŸtÄ±rarak, belirli verilere kolayca eriÅŸmenizi saÄŸlar. YukarÄ±daki Ã¶rnekler ve ipuÃ§larÄ±yla Beautiful Soup'u projelerinizde rahatlÄ±kla kullanabilirsiniz. ğŸš€